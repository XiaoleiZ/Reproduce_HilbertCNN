{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo HibertCNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XiaoleiZ/Reproduce_HilbertCNN/blob/master/Demo_HibertCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "CAMk30an3hwZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Implement HilbertCNN\n",
        "\n",
        "Paper: [An Image representation based on convolutional network for DNA classification](https://arxiv.org/pdf/1806.04931.pdf)\n",
        "\n",
        "Method Summary: Transform 1D-DNA sequence into 2D image to improve the classification performance of using CNN\n",
        "\n",
        "Steps: \n",
        "\n",
        "1.Transformation from 1D sequence to 2D image\n",
        "\n",
        "2.CNN classification network\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "7ND6wvI14vmS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# DNA sequence representation\n",
        "\n",
        "1.Represent a sequence as a list of k-mers\n",
        "\n",
        "2.Transform each k-mer into a one-hot vector\n",
        "-> sequence is represented as a list of one-hot vector\n",
        "\n",
        "3.Use Hilbert Curves to assign each element of the list of k-mers to a pixel in an image"
      ]
    },
    {
      "metadata": {
        "id": "gA0ZZKMI5rCV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import Sequential,Model\n",
        "from keras.layers import Activation, Dense,Dropout,Input,Conv2D, BatchNormalization,AveragePooling2D,Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import urllib\n",
        "import re\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vexQNdBz6TKR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def kmerize(sequence, k=4):\n",
        "    \n",
        "    ###Description: represent a sequence as list of k-mers\n",
        "    ###Input: sequence (string), \n",
        "    ###       parameter k (k>=1), use 4 as default as shown in the paper.\n",
        "    ###Output: a list of k-mer strings (array)\n",
        "    \n",
        "    #include the list of k-mers\n",
        "    if k <1 or not int(k):\n",
        "      raise ValueError(\"k must be an integer larger than zero\");\n",
        "    \n",
        "    kmer_list = [];\n",
        "    \n",
        "    l=len(sequence);\n",
        "    for i in range(0,l-k+1): # 0...l-k, the last kmer is the segment between l-k,l\n",
        "      kmer_list.append(sequence[i:i+k]);\n",
        "    \n",
        "    return kmer_list;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XBMT_JqKB-4W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_four_mer_ohv(k=4):\n",
        "  \n",
        "  ###Description: create a dictionary to store the one-hot-vector encoding (value) for each 4-mer (key)\n",
        "  \n",
        "  four_mer_list=[];\n",
        "  base = ['A','C','G','T'];\n",
        "  for n1 in base:\n",
        "    for n2 in base:\n",
        "      for n3 in base:\n",
        "        for n4 in base:\n",
        "          four_mer_list.append(n1+n2+n3+n4);\n",
        "  \n",
        "  four_mer_dict ={};\n",
        "  l=len(four_mer_list);\n",
        "  for i,x in enumerate(four_mer_list):\n",
        "    vector=np.zeros(l);\n",
        "    vector[i]=1;\n",
        "    four_mer_dict[x]=vector;\n",
        "    \n",
        "  return four_mer_dict;\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tTyPaQvX8Mwo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot_vectorize(kmer_list,four_mer_dict):\n",
        "  \n",
        "  ###Description: transfrom a list of k-mers into a list of one-hot-vectors\n",
        "  ###Input: a list of k-mers representing a sequence\n",
        "  ###       a dictionary created beforehand to store the one-hot-vector encoding for each possible kmer\n",
        "  ###       (4-mer is used here)\n",
        "  ###Output: a list of one-hot-encoding vectors representing the sequence\n",
        "  return list(map(lambda x: four_mer_dict[x], kmer_list))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tIVRJJ1cdfPG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def hilbert_curve (n):\n",
        "    #Description: Implementation of Hilbert space filling curve of order log2(n) \n",
        "    #             (number of cells: n*n) to map a distance in 1-D to coordinate in 2D array\n",
        "    #Input: the number of cells in each dimension\n",
        "    #return: 2D array - for each coordinate x,y, the value is the position in 1D the hlbert map corresponds to.\n",
        "    #\n",
        "    if n==2:\n",
        "        return np.array([[0,3],[1,2]],int)\n",
        "    unit=hilbert_curve(int(n/2));\n",
        "    #the number of cells in each quardrant\n",
        "    step = int(n**2/4)\n",
        "    #the directions of the four quardrant given in the paper\n",
        "    ########################\n",
        "    ### a # d #\n",
        "    ###   #   # \n",
        "    ########################\n",
        "    ### b # c #\n",
        "    ###   #   #\n",
        "    ########################\n",
        "    \n",
        "    #for the first quadrant: anti-closewise rotate 90 degree\n",
        "    a = np.flipud(np.rot90(unit));\n",
        "    b = unit +step\n",
        "    c = unit +step*2\n",
        "    d = np.fliplr(np.rot90(unit)) +step*3\n",
        "    #stack the four quardrant together\n",
        "    new = np.concatenate((np.concatenate((a,b),axis=0),np.concatenate((d,c),axis=0)),axis=1)\n",
        "    return new  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CZZ-6AJsqUqa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pixelize_seqs(seqs,k=4):\n",
        "  #Description: give a batch of sequence, process these sequences into images\n",
        "  #Input: a list of sequences, each element is a string\n",
        "  #Ouput: a list of images, each element is an image corresponding to the sequence\n",
        "  \n",
        "  #crop the hilbert curve\n",
        "  curve=hilbert_curve(2**5)[:,0:16]\n",
        "  n_height,n_width,n_depth = curve.shape+(256,)\n",
        "  \n",
        "  img_list = np.zeros((len(seqs),n_height,n_width,n_depth))\n",
        "  \n",
        "  for i in range(len(seqs)):\n",
        "    kmer_list=kmerize(seqs[i],k);\n",
        "    four_mer_dict=create_four_mer_ohv(k)\n",
        "    ohv_list=one_hot_vectorize(kmer_list,four_mer_dict)\n",
        "    for j in range(len(ohv_list)):\n",
        "    #find the coordinate in the img\n",
        "      img_list[i,np.where(curve==j)]=ohv_list[j]\n",
        "  \n",
        "  return img_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3OfeI60Ix3Jd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_data(file):\n",
        "  if re.search(\"^http\", file):\n",
        "    f = urllib.request.urlopen(file)\n",
        "  else: \n",
        "    f=open(file)\n",
        "  content = f.readlines()\n",
        "  line=1\n",
        "  name=[]\n",
        "  seq=[]\n",
        "  label=[]\n",
        "  for x in content:\n",
        "    x=x.strip()\n",
        "    x=x.decode('utf-8')\n",
        "    if line % 3 == 1:\n",
        "      name = name + [x[1:]] #remove \">\"\n",
        "    elif line % 3 == 2:\n",
        "      seq = seq + [x]\n",
        "    elif line % 3 == 0:\n",
        "      label = label + [x]\n",
        "    line += 1\n",
        "  \n",
        "  return name,seq,label\n",
        "\n",
        "def one_hot_vector(label):\n",
        "  '''\n",
        "  Description: given a vector of label (either 0 or 1), transform it into one-hot vector encoding\n",
        "  \n",
        "  '''\n",
        "  label_class = np.zeros((len(label),2))\n",
        "  for i in range(len(label)):\n",
        "    if label[i]:\n",
        "      label_class[i][0]=1\n",
        "    else:\n",
        "      label_class[i][1]=1\n",
        "  \n",
        "  return label_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5pUrdOIes310",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Define the architecture  of Convolutional Neural Network  \n",
        "\n",
        "Captured from the original paper. \n",
        "\n",
        "![Hilbert CNN architecture](https://raw.githubusercontent.com/XiaoleiZ/Reproduce_HilbertCNN/master/HilbertCNN_architecture.png)"
      ]
    },
    {
      "metadata": {
        "id": "D007mmRJXIFt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def res_block(inputs,k1,k2,link,out):\n",
        "  #residual block include: conv,bn,af,conv,bn\n",
        "  #\n",
        "  x=inputs\n",
        "  x=Conv2D(filters=link,kernel_size=(k1,k1),padding='same',input_shape=inputs.shape)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Activation('elu')(x)\n",
        "  x=Conv2D(filters=out,kernel_size=(k2,k2),padding='same')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  \n",
        "  return x\n",
        "\n",
        "\n",
        "def Computational_block(input_shape,k1,k2,k3,k4,link,out):\n",
        "  #Description: build the computational block: \n",
        "  #first the sum of two residul block and one identitiy map \n",
        "  #BatchNormalization->Activation Function\n",
        "  \n",
        "  #Input:\n",
        "  #input_shape\n",
        "  #k1, k2 - respective filter size of the first and second conv layers in the first residual block\n",
        "  #k3, k4 - respective filter size of the first and second conv layers in the second residual block \n",
        "  #link - dimension of output of the first conv layer\n",
        "  #out - dimension of output of the residual block\n",
        "  \n",
        "  #two residual blocks\n",
        "  inputs=Input(input_shape)\n",
        "  x1=res_block(inputs,k1,k2,link,out)\n",
        "  x2=res_block(inputs,k3,k4,link,out)\n",
        "  if input_shape[-1]==out:\n",
        "    x=keras.layers.add([inputs,x1,x2])\n",
        "  else:\n",
        "    x_input=Conv2D(filters=out,kernel_size=(1,1),padding='same',input_shape=inputs.shape)(inputs)\n",
        "    x=keras.layers.add([x_input,x1,x2])\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Activation('elu')(x)\n",
        "  \n",
        "  model=Model(inputs=inputs,outputs=x)\n",
        "  \n",
        "  return model\n",
        "  \n",
        "  \n",
        "def HCNN():\n",
        "  '''\n",
        "  Input: 32*16*256 images\n",
        "  (1) Conv1: 7*7 conv, BN -> (output size) 32*16*64\n",
        "  (2) Conv2: 5*5 conv, BN -> (output size)\n",
        "  '''\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=64,kernel_size=(7,7),padding='same',input_shape=(32,16,256)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(filters=64,kernel_size=(5,5),padding='same',input_shape=(32,16,64)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('elu'))\n",
        "  model.add(AveragePooling2D(pool_size=(2,2),strides=2))\n",
        "  model.add(Computational_block(input_shape=[16,8,64],k1=8,k2=4,k3=4,k4=3,link=4,out=32))\n",
        "  model.add(Computational_block(input_shape=[16,8,32],k1=3,k2=3,k3=3,k4=3,link=4,out=32))\n",
        "  model.add(AveragePooling2D(pool_size=(2,2),strides=2))\n",
        "  model.add(Computational_block(input_shape=[8,4,32],k1=2,k2=4,k3=4,k4=3,link=4,out=32))\n",
        "  model.add(Computational_block(input_shape=[8,4,32],k1=2,k2=2,k3=2,k4=2,link=4,out=32))\n",
        "  model.add(Computational_block(input_shape=[8,4,32],k1=3,k2=2,k3=2,k4=3,link=4,out=32))\n",
        "  model.add(AveragePooling2D(pool_size=(2,2),strides=2))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('elu'))\n",
        "  model.add(AveragePooling2D(pool_size=(2,2),strides=2))\n",
        "  #the first classification layer\n",
        "  model.add(Flatten())\n",
        "  model.add(Activation('elu')) #mentioned in the paper but not in the code\n",
        "  model.add(Dropout(rate=0.5))\n",
        "  #the second classification layer\n",
        "  model.add(Dense(100))\n",
        "  model.add(Activation('elu'))\n",
        "  model.add(Dropout(rate=0.5))\n",
        "  #the third classification layer\n",
        "  model.add(Dense(50))\n",
        "  model.add(Activation('elu'))\n",
        "  model.add(Dropout(rate=0.5))\n",
        "  model.add(Dense(2,activation='softmax'))\n",
        "    \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H3lUG4i5vf9w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load the data"
      ]
    },
    {
      "metadata": {
        "id": "0GrOUCdA1qmj",
        "colab_type": "code",
        "outputId": "ae61c140-e69d-4401-f09e-a1272a2296aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Read the data\n",
        "\n",
        "demo_file_url = 'https://raw.githubusercontent.com/XiaoleiZ/Reproduce_HilbertCNN/master/data/H4_1000.txt'\n",
        "name,seq,label=read_data(demo_file_url)\n",
        "imgs=pixelize_seqs(seq,k=4)\n",
        "label = np.reshape(np.array(list(map(int,label))),(len(label),1))\n",
        "label = one_hot_vector(label)\n",
        "# check the dimension\n",
        "print(\"Transformed image shape:\"+str(imgs.shape))\n",
        "print(\"Label class shape:\"+str(label.shape))\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transformed image shape:(1000, 32, 16, 256)\n",
            "Label class shape:(1000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m1E5o-X7voNG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Split the data into training (2/3) and test (1/3) dataset"
      ]
    },
    {
      "metadata": {
        "id": "E3XV3oj411dQ",
        "colab_type": "code",
        "outputId": "d9f91a07-e7f1-4e55-a473-bab8ba6e7766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "## train, test data split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "imgs, label, test_size=0.33, random_state=42)\n",
        "\n",
        "print(\"Training data feature shape:\"+str(X_train.shape))\n",
        "print(\"Test data feature shape:\"+str(X_test.shape))\n",
        "print(\"Training data label shape:\"+str(y_train.shape))\n",
        "print(\"Test data label shape:\"+str(y_test.shape))\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data feature shape:(670, 32, 16, 256)\n",
            "Test data feature shape:(330, 32, 16, 256)\n",
            "Training data label shape:(670, 2)\n",
            "Test data label shape:(330, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zY18AfeqyE6m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hcnn=HCNN()\n",
        "hcnn.compile(optimizer=Adam(lr=0.003),loss='categorical_crossentropy',metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RoHBMb8v5j6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Network summary"
      ]
    },
    {
      "metadata": {
        "id": "cJ6r8EsZfi4b",
        "colab_type": "code",
        "outputId": "efd486cf-d19c-414e-890b-c7917aa6d0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "cell_type": "code",
      "source": [
        "hcnn.summary()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_70 (Conv2D)           (None, 32, 16, 64)        802880    \n",
            "_________________________________________________________________\n",
            "batch_normalization_85 (Batc (None, 32, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_71 (Conv2D)           (None, 32, 16, 64)        102464    \n",
            "_________________________________________________________________\n",
            "batch_normalization_86 (Batc (None, 32, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_61 (Activation)   (None, 32, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_13 (Averag (None, 16, 8, 64)         0         \n",
            "_________________________________________________________________\n",
            "model_16 (Model)             (None, 16, 8, 32)         26248     \n",
            "_________________________________________________________________\n",
            "model_17 (Model)             (None, 16, 8, 32)         5096      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_14 (Averag (None, 8, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "model_18 (Model)             (None, 8, 4, 32)          6248      \n",
            "_________________________________________________________________\n",
            "model_19 (Model)             (None, 8, 4, 32)          2536      \n",
            "_________________________________________________________________\n",
            "model_20 (Model)             (None, 8, 4, 32)          3816      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_15 (Averag (None, 4, 2, 32)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_112 (Bat (None, 4, 2, 32)          128       \n",
            "_________________________________________________________________\n",
            "activation_77 (Activation)   (None, 4, 2, 32)          0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_16 (Averag (None, 2, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "activation_78 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 100)               6500      \n",
            "_________________________________________________________________\n",
            "activation_79 (Activation)   (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "activation_80 (Activation)   (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 961,580\n",
            "Trainable params: 960,220\n",
            "Non-trainable params: 1,360\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ExwbYXv-v_0p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training and testing: use 128 samples in each batch and 10 as the epoch size"
      ]
    },
    {
      "metadata": {
        "id": "T4Lp3MqZ5MRv",
        "colab_type": "code",
        "outputId": "447c292a-e2b5-4283-8af7-b0efacf4c815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "hcnn.fit(X_train,y_train,batch_size=128,epochs=10,verbose=1,shuffle=True,validation_data=(X_test,y_test))\n",
        "score = hcnn.evaluate(X_test,y_test,verbose=0)\n",
        "print('Test accuracy:',score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 670 samples, validate on 330 samples\n",
            "Epoch 1/10\n",
            "670/670 [==============================] - 66s 99ms/step - loss: 0.9668 - acc: 0.4821 - val_loss: 0.7461 - val_acc: 0.5697\n",
            "Epoch 2/10\n",
            "670/670 [==============================] - 55s 82ms/step - loss: 0.8587 - acc: 0.5239 - val_loss: 0.8488 - val_acc: 0.4303\n",
            "Epoch 3/10\n",
            "670/670 [==============================] - 54s 81ms/step - loss: 0.8281 - acc: 0.5761 - val_loss: 0.8667 - val_acc: 0.4303\n",
            "Epoch 4/10\n",
            "256/670 [==========>...................] - ETA: 29s - loss: 0.7699 - acc: 0.5742"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}